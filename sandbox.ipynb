{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminfarcy/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Reading ...\n",
      "-- Done\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lib.model import train_lgbm_fold_classif, plot_importances\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from lib.constants import DATA_FOLDER, TMP_FOLDER, SUBMISSION_FOLDER\n",
    "from lib.dataload import load_data\n",
    "import numpy as np\n",
    "from lib.utils import make_submission_from_hdf\n",
    "df_train, df_target, df_test = load_data(read=True, reduce_mem=False)\n",
    "df_train['is_train'] = 1\n",
    "df_test['is_train'] = 0\n",
    "train_test = pd.concat([df_train, df_test], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>nmods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>is_train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>target</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>var_68</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>var_91</td>\n",
       "      <td>8197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>var_108</td>\n",
       "      <td>8651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>var_103</td>\n",
       "      <td>9634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>var_12</td>\n",
       "      <td>9737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>var_148</td>\n",
       "      <td>10894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>var_161</td>\n",
       "      <td>11359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>var_71</td>\n",
       "      <td>13968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        param  nmods\n",
       "202  is_train      2\n",
       "1      target      2\n",
       "70     var_68    461\n",
       "93     var_91   8197\n",
       "110   var_108   8651\n",
       "105   var_103   9634\n",
       "14     var_12   9737\n",
       "150   var_148  10894\n",
       "163   var_161  11359\n",
       "73     var_71  13968"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmods_data = []\n",
    "for param in train_test.columns:\n",
    "    nmods = train_test[param].nunique()\n",
    "    nmods_data.append(nmods)\n",
    "\n",
    "df_nmods = pd.DataFrame(list(train_test.columns), columns=['param'])\n",
    "df_nmods['nmods'] = nmods_data\n",
    "\n",
    "sel_cols = list(set(df_nmods.columns) - set(['is_train', 'target']))\n",
    "\n",
    "look_cols = list(df_nmods[sel_cols].sort_values('nmods').head(30)['param'].values[2:])\n",
    "df_nmods.sort_values('nmods').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_cols = []\n",
    "for col in look_cols:\n",
    "    colname = 'count_' + col\n",
    "    count_cols.append(colname)\n",
    "    tmp = (\n",
    "        pd.DataFrame(train_test.groupby([col])['ID_code']\n",
    "                     .count().reset_index()\n",
    "                     .rename(columns={'ID_code': colname}))\n",
    "    )\n",
    "    train_test = train_test.merge(tmp, on=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in count_cols:\n",
    "    df_a = pd.cut(train_test[col], train_test[col].nunique()).value_counts().sort_index()\n",
    "    df_a = df_a.reset_index().rename(columns={'index': 'bin'}).reset_index()\n",
    "    df_a['diff'] = df_a[col].diff().fillna(0)\n",
    "    df_a['delta_0'] = np.around((df_a[col] - 0 )/ (df_a['index'] + 1), decimals=0)\n",
    "    \n",
    "    step = (train_test[col].max()-train_test[col].min())/train_test[col].nunique()\n",
    "    tmp2 = pd.DataFrame(train_test[col].drop_duplicates()).sort_values(by=col)\n",
    "    group_col = 'group_' + col\n",
    "    tmp2[group_col] = tmp2[col].apply(lambda x: int(df_a.iloc[np.minimum(int(x/step),\n",
    "                                                  train_test[col].nunique()-1), 4]))\n",
    "    train_test = train_test.merge(tmp2, on=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = ['target', 'ID_code', 'is_train']\n",
    "selected_cols = list(set(df_train.columns) - set(remove_cols))\n",
    "print(selected_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_train.iloc[0, 2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0, 200), df_train.iloc[10, 2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0, 200), df_train.iloc[100, 2:-1].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import spline, CubicSpline\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "xk = spline(np.arange(0, 200).astype('float'),\n",
    "       df_train.iloc[10, 2:-1].sort_values().values.astype('float'),\n",
    "       np.arange(0, 200).astype('float')\n",
    "      )\n",
    "plt.plot(np.arange(0, 200), xk)\n",
    "plt.plot(np.arange(0, 200), df_train.iloc[10, 2:-1].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = CubicSpline(np.arange(0, 200).astype('float'), df_train.iloc[10, 2:-1].sort_values().values.astype('float'))\n",
    "plt.plot(np.arange(0, 200), cs(np.arange(0, 200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "data_dict['integral'] = []\n",
    "data_dict['residual'] = []\n",
    "data_dict['left_derivative'] = []\n",
    "data_dict['center_derivative'] = []\n",
    "data_dict['right_derivative'] = []\n",
    "\n",
    "lent = len(train_test)\n",
    "sub_train_test = train_test[selected_cols]\n",
    "for index, row in enumerate(range(lent)):\n",
    "    us = UnivariateSpline(np.arange(0, 200).astype('float'),\n",
    "                      sub_train_test.iloc[row, :].sort_values().values.astype('float'),\n",
    "                      k=5\n",
    "                     )\n",
    "    data_dict['integral'].append(us.integral(0, 199))\n",
    "    data_dict['residual'].append(us.get_residual())\n",
    "    data_dict['left_derivative'].append(us.derivatives(10)[1])\n",
    "    data_dict['center_derivative'].append(us.derivatives(100)[1])\n",
    "    data_dict['right_derivative'].append(us.derivatives(189)[1])\n",
    "    if index % 5000 == 0:\n",
    "        print(index/lent*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_test.merge(pd.DataFrame(data_dict), on=train_test.index)\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_dict).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columnwise features\n",
    "train_test['min_col'] = train_test[selected_cols].min(axis=1)\n",
    "train_test['max_col'] = train_test[selected_cols].max(axis=1)\n",
    "train_test['std_col'] = train_test[selected_cols].std(axis=1)\n",
    "train_test['var_col'] = train_test[selected_cols].var(axis=1)\n",
    "train_test['mean_col'] = train_test[selected_cols].mean(axis=1)\n",
    "train_test['median_col'] = train_test[selected_cols].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"- Resplit train/test\")\n",
    "train = train_test[train_test['is_train'] == 1]\n",
    "test = train_test[train_test['is_train'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "remove_cols = ['target', 'ID_code', 'is_train']\n",
    "selected_cols = list(set(df_train.columns) - set(remove_cols))\n",
    "pca_result = pca.fit_transform(train_test[selected_cols])\n",
    "\n",
    "print(pca.explained_variance_ratio_)  \n",
    "print(pca.singular_values_)  \n",
    "\n",
    "print(\"Total explained variance:\", np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.scatter(x=pca_result[:, 0], y=pca_result[:, 1], marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['pca_0_0'] = np.around(pca_result[:, 0], decimals=0)\n",
    "train_test['pca_0_1'] = np.around(pca_result[:, 1], decimals=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test['pca_0_0'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(pca_result[:, 0], pca_result[:, 1], kind=\"hex\", color=\"#4CB391\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "X = pca_result\n",
    "\n",
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "# #############################################################################\n",
    "# Plot result\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor=tuple(col), markersize=1)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor=tuple(col), markersize=1)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"- Resplit train/test\")\n",
    "train_test = tmp\n",
    "train = train_test[train_test['is_train'] == 1]\n",
    "test = train_test[train_test['is_train'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_hdf('./data_tmp/new_train.hdf', 'df')\n",
    "test.to_hdf('./data_tmp/new_test.hdf', 'df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "remove_cols = ['target', 'ID_code']\n",
    "features = list(set(train.columns) - set(remove_cols) - set(selected_cols))\n",
    "\n",
    "importances, df_oof_preds, df_preds, filename = train_lgbm_fold_classif(train, test, features, train['target'],\n",
    "                              repeat_cv=1, n_splits=4,\n",
    "                              n_max_estimators=10000\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importances(importances, num_features=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ID_code'].reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_file = df_preds.merge(test['ID_code'].reset_index(), on=df_preds.index)[['ID_code', 0]].rename(columns={0:'target'})\n",
    "df_pred_file.to_csv('./data_tmp/test_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'preds_lgbm_classif_CV_0.88763_TR_0.98783'\n",
    "filename = 'preds_lgbm_classif_CV_0.89800_TR_0.91159'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_submission_from_hdf('preds_lgbm_classif_CV_0.89810_TR_0.91029', test['ID_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lgbm_classif_CV_0.89810_TR_0.91029.hdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
